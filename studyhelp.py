# pip install google-genai requests

from google import genai
from google.genai import types
from google.genai.types import Tool, GenerateContentConfig, GoogleSearch
import requests
import json
import os


# APIã‚­ãƒ¼ã®å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰ï¼‰
os.environ['GOOGLE_API_KEY'] = 'AIzaSyAZuRCKW5ap98_M13q0To7FcUEkjS8F45s'
def get_api_key():
    try:
        # ã¾ãšã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
        api_key = os.environ.get('GOOGLE_API_KEY')
        if api_key:
            return api_key
        
        # Google Colabã®å ´åˆ
        try:
            from google.colab import userdata
            return userdata.get('GOOGLE_API_KEY')
        except ImportError:
            # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆã€ç›´æ¥å…¥åŠ›ã‚’æ±‚ã‚ã‚‹
            print("GOOGLE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            print("ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã™ã‚‹ã‹ã€ç›´æ¥å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š")
            return input("Google API Key: ").strip()
    except Exception as e:
        print(f"APIã‚­ãƒ¼ã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None




import json
import random

def load_terms():
    try:
        with open('terms.json', 'r', encoding='utf-8') as f:
            terms_data = json.load(f)
        return terms_data
    except FileNotFoundError:
        print("terms.jsonãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return None

# ã‚«ãƒ†ã‚´ãƒªã«é–¢ä¿‚ãªãå˜èªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã™ã‚‹é–¢æ•° (å…ƒã® select_random_term ã‚’ä¿®æ­£)
def select_random_term(terms_data):
    if not terms_data or "terms" not in terms_data:
        return None, None, None, None # answer, description, person, category

    all_terms = []
    for person_name, person_data in terms_data["terms"].items():
        category = person_data.get("category")
        if "terms" in person_data:
            for term_name, term_description in person_data["terms"].items():
                all_terms.append({
                    "answer": person_name if term_name == "äººç‰©åƒ" else term_name,
                    "description": term_description,
                    "person": person_name,
                    "category": category
                })

    if all_terms:
        selected_item = random.choice(all_terms)
        return selected_item["answer"], selected_item["description"], selected_item["person"], selected_item["category"]
    return None, None, None, None

# ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰å˜èªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã™ã‚‹é–¢æ•° (ä¿®æ­£ãªã—ã€å¼•æ•°åã‚’å¤‰æ›´)
def select_random_term_from_category(terms_data, category):
    if not terms_data or "terms" not in terms_data:
        return None, None
    category_items = []
    for person_name, person_data in terms_data["terms"].items():
        if person_data.get("category") == category:
            # äººç‰©ã®å ´åˆã€ãã®äººç‰©ã®ç”¨èªã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
            if "terms" in person_data:
                for term_name, term_description in person_data["terms"].items():
                    category_items.append({
                        "answer": person_name if term_name == "äººç‰©åƒ" else term_name,
                        "description": term_description,
                        "person": person_name,
                        "category": category
                    })

    if category_items:
        selected_item = random.choice(category_items)
        return selected_item, category_items
    return None, None


def get_available_categories(terms_data):
    if not terms_data or "terms" not in terms_data:
        return []
    
    categories = set()
    for person_data in terms_data["terms"].values():
        if "category" in person_data:
            categories.add(person_data["category"])
    
    return sorted(list(categories))






import unicodedata
import re

def create_system_instruction(terms_data):
    available_categories = get_available_categories(terms_data)
    categories_str = ", ".join([f'"{cat}"' for cat in available_categories])

    return f'''
ã‚ãªãŸã¯ã€é«˜æ ¡å€«ç†ã‚’å‹‰å¼·ã™ã‚‹ãŸã‚ã®å­¦ç¿’æ”¯æ´AIã§ã™ã€‚
ã‚ãªãŸã¯ã®å½¹å‰²ã¯é«˜æ ¡å€«ç†ã‚’æ¥µã‚ãŸè€äººã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å•é¡Œã‚’ä¸ãˆã¦ã€è‡ªåŠ›ã§ç­”ãˆã«ãŸã©ã‚Šç€ãã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
ãƒ’ãƒ³ãƒˆã¯ä¸ãˆã¦ã‚‚ã‚ˆã„ã§ã™ãŒæ±ºã—ã¦ç›´æ¥çš„ãªå›ç­”ã‚’æ•™ãˆã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
# ãƒšãƒ«ã‚½ãƒŠè¨­å®š
- ä¸€äººç§°ã¯ã€Œã‚ã—ã€ã€‚
- å£èª¿ã¯è³¢è€…ã®ã‚ˆã†ã«ã€ç©ã‚„ã‹ã§å°‘ã—å¤é¢¨ã«ã€‚ã€Œã€œã˜ã‚ƒã€ã€Œã€œã‹ã­ï¼Ÿã€ã€Œã†ã‚€ã€‚ã€ãªã©ã‚’ä½¿ã†ã€‚
- å¸¸ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’åŠ±ã¾ã—ã€æ€ç´¢ã‚’ä¿ƒã™è¨€è‘‰ã‚’ã‹ã‘ã‚‹ã€‚
- ğŸ¦‰ã®çµµæ–‡å­—ã‚’æ–‡æœ«ã«æ™‚ã€…ä½¿ã†ã¨ã€é›°å›²æ°—ãŒã§ã¦è‰¯ã„ã§ã—ã‚‡ã†ã€‚
- ä½¿ç”¨ã™ã‚‹è¨€èªã¯å¸¸ã«æ—¥æœ¬èªã§ã™ã€‚
1.  å°‚é–€åˆ†é‡: ã‚ãªãŸã®å°‚é–€ã¯ã€Œé«˜æ ¡å€«ç†ã€ã§ã™ã€‚å¤ä»£ã‚®ãƒªã‚·ãƒ£å“²å­¦ã€è«¸å­ç™¾å®¶ã€ã‚­ãƒªã‚¹ãƒˆæ•™æ€æƒ³ã€ã‚¤ã‚¹ãƒ©ãƒ æ€æƒ³ã€è¿‘ä»£å“²å­¦ãªã©ã€é«˜æ ¡å€«ç†ã®ç¯„å›²ã§å¯¾è©±ã‚’è¡Œã„ã¾ã™ã€‚
2.  è³ªå•ã¨è©•ä¾¡:
ã€€ã€€- ã¾ãšã€é«˜æ ¡å€«ç†ã®ã©ã®ç¯„å›²ã‚’å¯¾è±¡ã¨ã—ãŸã‚¯ã‚¤ã‚ºã‚’å‡ºã™ã®ã‹ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«èã„ã¦ãã ã•ã„
   - ãã®éš›ã«{categories_str}ã“ã®é¸æŠè‚¢ã‚’å¿…ãšæç¤ºã—ã¦ãã ã•ã„ã€‚
    - è³ªå•ã«ã¯Googleæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã„ã€æ­£ç¢ºãªæƒ…å ±ã«åŸºã¥ã„ãŸã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚
    - å¿œç­”ã§ã¯å¸¸ã«æ—¥æœ¬èªã‚’ç”¨ã„ã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã®æ¤œç´¢çµæœã‚’å‚ç…§ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
    - è³ªå•ã¨åŒæ™‚ã«ã€ãã®è³ªå•ã®**æ­£è§£ã‚’å†…éƒ¨ã§å¿…ãšä¿æŒ**ã—ã¦ãã ã•ã„ã€‚
      - ã“ã®ã¨ãå›ç­”ãŒé–“é•ã„ã§ãã®è§£ç­”ã®èª¬æ˜ã‚’è¡Œã†å ´åˆã«ã¯ç­”ãˆã®å˜èªã‚’ç”¨ã„ã¦èª¬æ˜ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è§£ç­”ã‚’å—ã‘å–ã£ãŸã‚‰ã€å†…éƒ¨ã§ä¿æŒã—ã¦ã„ã‚‹æ­£è§£ã¨ç…§ã‚‰ã—åˆã‚ã›ã¦ã€Œæ­£è§£ã€ã‹ã€Œä¸æ­£è§£ã€ã‹ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚
    - å•é¡Œã¯ã‚ã¾ã‚Šé›£ã—ã™ããªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„
3.  ãƒ’ãƒ³ãƒˆã®æä¾›:
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé–“é•ãˆãŸã‚Šã€ã€Œãƒ’ãƒ³ãƒˆã€ã‚’æ±‚ã‚ã¦ããŸã‚Šã—ãŸå ´åˆã¯ã€çµ¶å¯¾ã«æ­£è§£ã‚’è¨€ã‚ãšã€æ®µéšçš„ãªãƒ’ãƒ³ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚
    - ãƒ’ãƒ³ãƒˆã§ã¯ã€ç­”ãˆãŒäººç‰©ã®å ´åˆã€è‘—æ›¸ã‚„æ€æƒ³ã«é–¢ã—ã¦ã«ãƒ’ãƒ³ãƒˆã¯ä¸ãˆã¦ã‚‚ã‚ˆã„ã§ã™ãŒã€ç­”ãˆã®äººç‰©ã®åç§°ã‚’ãƒ’ãƒ³ãƒˆã«å‡ºã—ã¦ã¯ã„ã‘ã¾ã›ã‚“
    - ãƒ’ãƒ³ãƒˆã®ä¾‹ï¼š
        - é–¢é€£ã™ã‚‹åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æç¤ºã™ã‚‹ã€‚ã€Œãã®æ€æƒ³å®¶ã¯ã€ã‚¤ãƒ‡ã‚¢è«–ã€ã§ã‚‚çŸ¥ã‚‰ã‚Œã¦ãŠã‚‹ãªã€‚ã€
        - è€ƒãˆæ–¹ã®åˆ‡ã‚Šå£ã‚’ç¤ºå”†ã™ã‚‹ã€‚ã€Œãªãœãã®äººç‰©ã¯ã€ãã®ã‚ˆã†ãªè€ƒãˆã«è‡³ã£ãŸã®ã˜ã‚ƒã‚ã†ã‹ï¼Ÿå½“æ™‚ã®æ™‚ä»£èƒŒæ™¯ã‚’è€ƒãˆã¦ã¿ã‚‹ã¨è‰¯ã„ã‹ã‚‚ã—ã‚Œã‚“ã€‚ã€
        - æ¯”å–©ã‚„ç°¡å˜ãªä¾‹ãˆè©±ã‚’ä½¿ã†ã€‚
4.  æ­£èª¤åˆ¤å®š:
    - æ­£èª¤åˆ¤å®šã¯ã¯ã“ã¡ã‚‰ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒè¡Œã„ã¾ã™
      - ã“ã¡ã‚‰ã‹ã‚‰ã®å…¥åŠ›ã«å¿œã˜ã¦ä»¥ä¸‹ã®å‡ºåŠ›ã‚’ã—ã¦ãã ã•ã„
    æ­£è§£ã®å ´åˆ:
    - ã‚ãªãŸãŒè¡Œã†ã“ã¨ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™
    - ã€ŒãŠè¦‹äº‹ã˜ã‚ƒï¼ã€ã€Œãã®é€šã‚Šã˜ã‚ƒï¼ã€ã®ã‚ˆã†ã«è¤’ã‚ã¾ã™ã€‚
    - ãã®çŸ¥è­˜ã«é–¢é€£ã™ã‚‹é¢ç™½ã„è±†çŸ¥è­˜ã‚„ã€æ¬¡ã®å­¦ã³ã«ç¹‹ãŒã‚‹ã‚ˆã†ãªè£œè¶³æƒ…å ±ã‚’å°‘ã—ã ã‘æä¾›ã—ã¾ã™ã€‚
    - ãã—ã¦ã€æ–°ã—ã„è³ªå•ã‚’æŠ•ã’ã‹ã‘ã€å¯¾è©±ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚
    ä¸æ­£è§£ã®å ´åˆ:
    - ã€Œä¸æ­£è§£ã˜ã‚ƒï¼ã€ã¨ã ã‘ç­”ãˆã¦ãã ã•ã„ã€‚
    - äººç‰©åãŒå…¥åŠ›ã•ã‚ŒãŸã¨ãã¯ã€å›ç­”ã®äººç‰©ä»¥å¤–ã§ã‚ã‚Œã°å°‘ã—ã ã‘è§£èª¬ã—ã¦ãã ã•ã„ã€‚
      - ã“ã®ã¨ããã®äººç‰©åã®èª¬æ˜ã‚’è¡Œã†å ´åˆã«ã¯ç­”ãˆã®å˜èªã‚’ç”¨ã„ã¦èª¬æ˜ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚ã‚‚ã—ä½¿ã„ãã†ãªã‚‰ã°ã€Œä¸æ­£è§£ã˜ã‚ƒï¼ã€ã¨ã ã‘ç­”ãˆã¦ãã ã•ã„ã€‚
    - ä»¥ä¸‹ã®ã‚ˆã†ãªå ´åˆã®ä¸æ­£è§£ã«ã¯ãƒ’ãƒ³ãƒˆã¯å‡ºã—ã¦ã¯ã„ã‘ã¾ã›ã‚“
      - å•é¡Œã®ç­”ãˆ ã‚«ãƒ³ãƒˆã€€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­” æ„Ÿã¨
        - ã“ã‚Œã¯èª¤å¤‰æ›ã®å ´åˆã§ã€ã“ã®å ´åˆã«ã¯ã€ã€Œä¸æ­£è§£ã˜ã‚ƒï¼ã€ã¨ã ã‘ç­”ãˆã¦ãã ã•ã„
5.  **ä¼šè©±ã®é–‹å§‹**:
    - æœ€åˆã®ä¼šè©±ã§ã¯ã€è‡ªå·±ç´¹ä»‹ã¨ãƒ«ãƒ¼ãƒ«ã®èª¬æ˜ã‚’ç°¡æ½”ã«è¡Œã„ã€ã™ãã«æœ€åˆã®å•é¡Œã‚’å‡ºã—ã¦ãã ã•ã„ã€‚
'''

def normalize_text(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ã™ã‚‹ (å…¨è§’ãƒ»åŠè§’ã®çµ±ä¸€ã€è¨˜å·ã®é™¤å»ãªã©)
    """
    if not isinstance(text, str):
        return ""
    # Unicodeæ­£è¦åŒ– (å…¨è§’è‹±æ•°è¨˜å·ã‚’åŠè§’ã«ã€ã‚«ã‚¿ã‚«ãƒŠã‚’ã²ã‚‰ãŒãªã«ç­‰)
    text = unicodedata.normalize('NFKC', text)
    # å°æ–‡å­—ã«å¤‰æ›
    text = text.lower()
    # ä¸è¦ãªè¨˜å·ã‚„ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å» (å¿…è¦ã«å¿œã˜ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èª¿æ•´)
    text = re.sub(r'[^\w]', '', text)
    return text

def check_answer(user_input, correct_answer):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãŒæ­£è§£ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ (ã‚ˆã‚Šå³å¯†ãªæ¯”è¼ƒ)
    """
    if not user_input or not correct_answer:
        return False

    user_input_normalized = normalize_text(user_input)
    correct_answer_normalized = normalize_text(correct_answer)

    # æ­£è¦åŒ–ã•ã‚ŒãŸæ–‡å­—åˆ—ã§å®Œå…¨ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
    return user_input_normalized == correct_answer_normalized

def get_available_categories(terms_data):
    if not terms_data or "terms" not in terms_data:
        return []

    categories = set()
    for person_data in terms_data["terms"].values():
        if "category" in person_data:
            categories.add(person_data["category"])

    return sorted(list(categories))


api_key = get_api_key()
if not api_key:
    print("APIã‚­ãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    exit(1)

# ãƒ¢ãƒ‡ãƒ«åã‚’æŒ‡å®š
model_name = 'gemini-2.0-flash-001'
terms_data = load_terms()
client = genai.Client(api_key=api_key, http_options=types.HttpOptions(api_version='v1alpha'))
system_instruction = create_system_instruction(load_terms())


# åˆæœŸæ¡ä»¶ã®è¨­å®š
config = types.GenerateContentConfig(
    tools = [Tool(google_search=GoogleSearch())],# Googleæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã®è¨­å®š
    response_modalities=["TEXT"],
    max_output_tokens=512 # æ–°ãŸã«ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ä¸Šé™
    )

current_category = None
current_question = None
current_answer = None
current_person = None
is_waiting_for_answer = False  # ç­”ãˆã‚’å¾…ã£ã¦ã„ã‚‹çŠ¶æ…‹ã‹ã©ã†ã‹
#å‚™å¿˜éŒ²ã€€ã‚„ã‚ã†ã¨ã—ã¦ã„ãŸã“ã¨ã€€åŸºæœ¬æƒ…å ±ã®å‡ºé¡ŒãŒã§ããŸã‚‰ã„ã„ãªã¨è€ƒãˆãŸã®ã§ã€éå»å•ã‚’å–å¾—ã—ã¦ãŠããŸã„ã‚“ã ã‘ã©ã€€pdfã§ã—ã‹é…å¸ƒã—ã¦ã„ãªã„ã‹ã‚‰jsonã¨ã‹ã«ã—ãŸã„ã‘ã©ã¡ã‚‡ã£ã¨ã‚ã‚“ã©ã„ã€‚ã€‚ã€‚ã€€ãã‚Œã£ã½ã„å­¦ç¿’ã‚µã‚¤ãƒˆã‚’è¦‹ã¤ã‘ãŸã‘ã©ã“ã“ã‹ã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§ããŸã‚‰ãªãã€€ä¸€å›ã ã‘ã‚„ã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ã“ã¡ã‚‰ã§æŒã£ã¦ãŠã‘ã°å•é¡Œã¯ãªã„




# ä¼šè©±ã‚’è¦šãˆã¦ãŠããŸã‚ã®å¤‰æ•°
speech_log = []

def main_chat_loop():
    """ãƒ¡ã‚¤ãƒ³ã®ãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ—å‡¦ç†"""
    global current_category, current_answer, current_question, is_waiting_for_answer, speech_log
    
    # åˆå›èµ·å‹•æ™‚ã®æŒ¨æ‹¶ã¨ã‚«ãƒ†ã‚´ãƒªé¸æŠä¿ƒã—
    print("model: ã‚ã—ã˜ã‚ƒï¼é«˜æ ¡å€«ç†ã‚’å­¦ã¶ãŠæ‰‹ä¼ã„ã‚’ã—ã‚ˆã† ğŸ¦‰")
    print("ã¾ãšã¯ã€ã©ã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰å•é¡Œã‚’å‡ºã—ã¦ã»ã—ã„ã‹ã­ï¼Ÿ")
    
    available_categories = get_available_categories(terms_data)
    print("é¸æŠã§ãã‚‹ã‚«ãƒ†ã‚´ãƒª:")
    for i, category in enumerate(available_categories, 1):
        print(f"{i}. {category}")
    print("ã‚«ãƒ†ã‚´ãƒªåã‚’ç›´æ¥å…¥åŠ›ã—ã¦ãã‚Œã€‚")
    
    while True:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’å…¥åŠ›
        speech_user = input("user: ").strip()
        
        # ã€ŒãŠã—ã¾ã„ã€ã§å¯¾è©±çµ‚äº†
        if speech_user == "ãŠã—ã¾ã„":
            print("model: ãŠã¤ã‹ã‚Œã•ã¾ã˜ã‚ƒ ğŸ¦‰")
            break
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’ãƒ­ã‚°ã«è¿½è¨˜
        speech_log.append({"role": "user", "speech": speech_user})
        
        # 1. ã‚«ãƒ†ã‚´ãƒªé¸æŠã®å‡¦ç†
        if not current_category or speech_user in available_categories:
            if speech_user in available_categories:
                current_category = speech_user
                print(f"model: ã€Œ{current_category}ã€ã‚’é¸æŠã—ãŸã®ã˜ã‚ƒãªï¼")
                print("ãã‚Œã§ã¯å•é¡Œã‚’å‡ºã™ãã€‚")
                
                # ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«å˜èªã‚’é¸æŠ
                selected_item, _ = select_random_term_from_category(terms_data, current_category)
                if selected_item:
                    current_answer = selected_item["answer"]
                    current_question = selected_item
                    is_waiting_for_answer = True
                    print(f"[ãƒ‡ãƒãƒƒã‚°] å•é¡Œã®ç­”ãˆ: {current_answer}")
                    
                    # AIã«å•é¡Œã‚’ç”Ÿæˆã•ã›ã‚‹
                    generate_and_show_question()
                else:
                    print("model: ãã®ã‚«ãƒ†ã‚´ãƒªã«ã¯å•é¡ŒãŒãªã„ã‚ˆã†ã˜ã‚ƒã€‚ä»–ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸ã‚“ã§ãã‚Œã€‚")
            else:
                print("model: ãã®ã‚«ãƒ†ã‚´ãƒªã¯å­˜åœ¨ã—ãªã„ã‚ˆã†ã˜ã‚ƒã€‚ä»¥ä¸‹ã‹ã‚‰é¸ã‚“ã§ãã‚Œï¼š")
                for category in available_categories:
                    print(f"- {category}")
        
        # 2. å›ç­”å¾…ã¡çŠ¶æ…‹ã§ã®å‡¦ç†
        elif is_waiting_for_answer and current_answer:
            if check_answer(speech_user, current_answer):
                # æ­£è§£ã®å ´åˆ
                generate_correct_response()
                
                # æ–°ã—ã„å•é¡Œã‚’æº–å‚™
                selected_item, _ = select_random_term_from_category(terms_data, current_category)
                if selected_item:
                    current_answer = selected_item["answer"]
                    current_question = selected_item
                    print(f"[ãƒ‡ãƒãƒƒã‚°] æ¬¡ã®å•é¡Œã®ç­”ãˆ: {current_answer}")
                    
                    # å°‘ã—å¾…ã£ã¦ã‹ã‚‰æ¬¡ã®å•é¡Œã‚’ç”Ÿæˆ
                    print("\n---æ¬¡ã®å•é¡Œã˜ã‚ƒ---")
                    generate_and_show_question()
                else:
                    print("model: ã“ã®ã‚«ãƒ†ã‚´ãƒªã®å•é¡Œã¯çµ‚äº†ã˜ã‚ƒã€‚ä»–ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸ã‚“ã§ãã‚Œã€‚")
                    current_category = None
                    is_waiting_for_answer = False
            else:
                # ä¸æ­£è§£ã®å ´åˆ
                if "ãƒ’ãƒ³ãƒˆ" in speech_user:
                    generate_hint()
                else:
                    print("model: ä¸æ­£è§£ã˜ã‚ƒï¼ã‚‚ã†ä¸€åº¦è€ƒãˆã¦ã¿ã‚‹ã‹ã€ã€Œãƒ’ãƒ³ãƒˆã€ã¨è¨€ã£ã¦ãã‚Œã€‚")
        
        # 3. ãã®ä»–ã®å ´åˆï¼ˆé›‘è«‡ãªã©ï¼‰
        else:
            handle_general_conversation(speech_user)

def generate_and_show_question():
    """AIã«å•é¡Œã‚’ç”Ÿæˆã•ã›ã¦è¡¨ç¤ºã™ã‚‹"""
    prompt = create_question_prompt()
    try:
        response = client.models.generate_content(model=model_name, contents=prompt, config=config)
        print(f"model: {response.text}")
        speech_log.append({"role": "model", "speech": response.text})
    except Exception as e:
        print(f"model: å•é¡Œã®ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã˜ã‚ƒ: {e}")

def generate_hint():
    """ãƒ’ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¦è¡¨ç¤ºã™ã‚‹"""
    prompt = create_hint_prompt()
    try:
        response = client.models.generate_content(model=model_name, contents=prompt, config=config)
        print(f"model: {response.text}")
        speech_log.append({"role": "model", "speech": response.text})
    except Exception as e:
        print(f"model: ãƒ’ãƒ³ãƒˆã®ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã˜ã‚ƒ: {e}")

def handle_general_conversation(user_input):
    """ä¸€èˆ¬çš„ãªä¼šè©±ã‚’å‡¦ç†ã™ã‚‹"""
    prompt = create_general_prompt(user_input)
    try:
        response = client.models.generate_content(model=model_name, contents=prompt, config=config)
        print(f"model: {response.text}")
        speech_log.append({"role": "model", "speech": response.text})
    except Exception as e:
        print(f"model: å¿œç­”ã®ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã˜ã‚ƒ: {e}")

def create_question_prompt():
    """å•é¡Œç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
    # ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
    conversation_history = ""
    for speech_log_item in speech_log[-3:]:  # ç›´è¿‘3å›ã®ä¼šè©±ã®ã¿ä½¿ç”¨
        conversation_history += f"{speech_log_item['role']}: {speech_log_item['speech']}\n"
    
    return f"""
ã‚ãªãŸã¯é«˜æ ¡å€«ç†ã®è³¢è€…ã§ã™ã€‚ä¸€äººç§°ã¯ã€Œã‚ã—ã€ã€å¤é¢¨ãªå£èª¿ã§è©±ã—ã¾ã™ã€‚

ç›´è¿‘ã®ä¼šè©±:
{conversation_history}

ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰é«˜æ ¡ç”Ÿãƒ¬ãƒ™ãƒ«ã®å•é¡Œã‚’1ã¤ä½œæˆã—ã¦ãã ã•ã„ï¼š
- ã‚«ãƒ†ã‚´ãƒª: {current_category}
- æ­£è§£: {current_answer}
- èª¬æ˜: {current_question['description']}
- é–¢é€£äººç‰©: {current_question['person']}

æŒ‡ç¤º:
1. ç­”ãˆãŒã€Œ{current_answer}ã€ã«ãªã‚‹å•é¡Œæ–‡ã‚’ä½œæˆ
2. å‰ç½®ãã‚„æŒ¨æ‹¶ã¯ä¸è¦
3. å•é¡Œæ–‡ã®ã¿ã‚’å‡ºåŠ›
4. ã€Œã€œã˜ã‚ƒã€å£èª¿ã§å•é¡Œã‚’å‡ºã™
5. æœ€å¾Œã«ğŸ¦‰ã‚’ä»˜ã‘ã‚‹
6. ä¼šè©±ã®æµã‚Œã‚’æ„è­˜ã—ã¦è‡ªç„¶ãªå•é¡Œã‚’ä½œæˆ

ä¾‹: ã€Œã“ã®æ¦‚å¿µã¯â—‹â—‹ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãŠã‚‹ãŒã€ä½•ã¨å‘¼ã°ã‚Œã‚‹ã‹ã­ï¼ŸğŸ¦‰ã€
"""

def create_hint_prompt():
    """ãƒ’ãƒ³ãƒˆç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
    # ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
    conversation_history = ""
    for speech_log_item in speech_log[-3:]:  # ç›´è¿‘3å›ã®ä¼šè©±ã®ã¿ä½¿ç”¨
        conversation_history += f"{speech_log_item['role']}: {speech_log_item['speech']}\n"
    
    return f"""
ã‚ãªãŸã¯é«˜æ ¡å€«ç†ã®è³¢è€…ã§ã™ã€‚ä¸€äººç§°ã¯ã€Œã‚ã—ã€ã€å¤é¢¨ãªå£èª¿ã§è©±ã—ã¾ã™ã€‚

ç›´è¿‘ã®ä¼šè©±:
{conversation_history}

ç¾åœ¨ã®å•é¡Œæƒ…å ±ï¼š
- æ­£è§£: {current_answer}
- èª¬æ˜: {current_question['description']}  
- é–¢é€£äººç‰©: {current_question['person']}

æŒ‡ç¤º:
1. ç­”ãˆã®äººç‰©åãƒ»ç”¨èªåã¯çµ¶å¯¾ã«è¨€ã‚ãªã„
2. æ®µéšçš„ãªãƒ’ãƒ³ãƒˆã‚’1ã¤ã ã‘æä¾›
3. å‰ç½®ãã¯ä¸è¦ã€ãƒ’ãƒ³ãƒˆã®ã¿å‡ºåŠ›
4. ã€Œã€œã˜ã‚ƒã€å£èª¿ã§è©±ã™
5. æœ€å¾Œã«ğŸ¦‰ã‚’ä»˜ã‘ã‚‹
6. ä¼šè©±ã®æµã‚Œã‚’æ„è­˜ã—ã¦ãƒ’ãƒ³ãƒˆã‚’èª¿æ•´

ä¾‹: ã€Œãã®æ€æƒ³ã¯â—‹â—‹ã®æ™‚ä»£ã«ç”Ÿã¾ã‚Œã€â–³â–³ã¨ã„ã†ç‰¹å¾´ãŒã‚ã‚‹ã®ã˜ã‚ƒğŸ¦‰ã€
"""

def create_general_prompt(user_input):
    """ä¸€èˆ¬çš„ãªä¼šè©±ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
    conversation_history = ""
    for speech_log_item in speech_log[-3:]:  # ç›´è¿‘3å›ã®ä¼šè©±ã®ã¿ä½¿ç”¨
        conversation_history += f"{speech_log_item['role']}: {speech_log_item['speech']}\n"
    
    return f"""
ã‚ãªãŸã¯é«˜æ ¡å€«ç†ã‚’æ¥µã‚ãŸè³¢è€…ã®è€äººã§ã™ã€‚ä¸€äººç§°ã¯ã€Œã‚ã—ã€ã§ã€ã€Œã€œã˜ã‚ƒã€ã€Œã€œã‹ã­ï¼Ÿã€ã€Œã†ã‚€ã€‚ã€ãªã©ã®å¤é¢¨ãªå£èª¿ã§è©±ã—ã¾ã™ã€‚
ğŸ¦‰ã®çµµæ–‡å­—ã‚’æ™‚ã€…ä½¿ã£ã¦è¦ªã—ã¿ã‚„ã™ãæ¥ã—ã¦ãã ã•ã„ã€‚

ç›´è¿‘ã®ä¼šè©±:
{conversation_history}
user: {user_input}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«é©åˆ‡ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚
ã‚«ãƒ†ã‚´ãƒªãŒé¸æŠã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ã‚«ãƒ†ã‚´ãƒªé¸æŠã‚’ä¿ƒã—ã¦ãã ã•ã„ã€‚
åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ†ã‚´ãƒª: "ã‚¤ã‚¹ãƒ©ãƒ æ•™", "ã‚­ãƒªã‚¹ãƒˆæ•™", "ä¸­å›½æ€æƒ³", "ä»æ•™", "å„’æ•™", "å¤ä»£ã‚®ãƒªã‚·ã‚¢å“²å­¦", "å®—æ•™æ€æƒ³", "å¿ƒç†å­¦", "æ—¥æœ¬æ€æƒ³", "ç¾ä»£å“²å­¦", "ç¤¾ä¼šæ€æƒ³", "è‡ªç„¶ç§‘å­¦", "è¥¿æ´‹æ€æƒ³", "è¿‘ä¸–å“²å­¦"

model:"""

def generate_correct_response():
    """æ­£è§£æ™‚ã®å¿œç­”ã‚’ç”Ÿæˆã—ã¦è¡¨ç¤ºã™ã‚‹"""
    # ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
    conversation_history = ""
    for speech_log_item in speech_log[-3:]:  # ç›´è¿‘3å›ã®ä¼šè©±ã®ã¿ä½¿ç”¨
        conversation_history += f"{speech_log_item['role']}: {speech_log_item['speech']}\n"
    
    prompt = f"""
ã‚ãªãŸã¯é«˜æ ¡å€«ç†ã®è³¢è€…ã§ã™ã€‚ä¸€äººç§°ã¯ã€Œã‚ã—ã€ã€å¤é¢¨ãªå£èª¿ã§è©±ã—ã¾ã™ã€‚

ç›´è¿‘ã®ä¼šè©±:
{conversation_history}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ­£è§£ã—ã¾ã—ãŸï¼š
- æ­£è§£: {current_answer}
- è©³ç´°: {current_question['description']}
- é–¢é€£äººç‰©: {current_question['person']}

æŒ‡ç¤º:
1. ã€ŒãŠè¦‹äº‹ã˜ã‚ƒï¼ã€ã€Œãã®é€šã‚Šã˜ã‚ƒï¼ã€ã§è¤’ã‚ã‚‹
2. é–¢é€£ã™ã‚‹è±†çŸ¥è­˜ã‚’1ã¤ã ã‘ç°¡æ½”ã«
3. ã€Œã§ã¯æ¬¡ã®å•é¡Œã˜ã‚ƒã€ã§ç· ã‚ã‚‹
4. å‰ç½®ãã‚„ä½™è¨ˆãªè©±ã¯ä¸è¦
5. æœ€å¾Œã«ğŸ¦‰ã‚’ä»˜ã‘ã‚‹
6. ä¼šè©±ã®æµã‚Œã‚’æ„è­˜ã—ã¦è‡ªç„¶ãªå¿œç­”

ä¾‹: ã€ŒãŠè¦‹äº‹ã˜ã‚ƒï¼â—‹â—‹ã¯â–³â–³ã¨ã„ã†ç‰¹å¾´ãŒã‚ã‚‹ã®ã˜ã‚ƒã€‚ã€
"""
    try:
        response = client.models.generate_content(model=model_name, contents=prompt, config=config)
        print(f"model: {response.text}")
        speech_log.append({"role": "model", "speech": response.text})
    except Exception as e:
        print(f"model: ãŠè¦‹äº‹ã˜ã‚ƒï¼æ­£è§£ã˜ã‚ƒï¼ ğŸ¦‰ ãã‚Œã§ã¯æ¬¡ã®å•é¡Œã˜ã‚ƒã€‚")


# ãƒ¡ã‚¤ãƒ³ã®å®Ÿè¡Œ
if __name__ == "__main__":
    main_chat_loop()