import json
import random
import unicodedata
import re
import os
from google import genai
from google.genai import types
from google.genai.types import Tool, GenerateContentConfig, GoogleSearch

# APIã‚­ãƒ¼ã®å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰ï¼‰
os.environ['GOOGLE_API_KEY'] =  # â† ãƒ†ã‚¹ãƒˆç”¨ã€‚å¿…è¦ãªã‚‰æœ‰åŠ¹åŒ–

def get_api_key():
    try:
        # ãƒ†ã‚¹ãƒˆç”¨ã«ç›´æ¥è¨­å®šï¼ˆæœ¬ç•ªã§ã¯å‰Šé™¤ã—ã¦ãã ã•ã„ï¼‰
        # os.environ['GOOGLE_API_KEY'] = 'YOUR_API_KEY_HERE'
        
        # ã¾ãšã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
        api_key = os.environ.get('GOOGLE_API_KEY')
        if api_key:
            return api_key
        
        # Google Colabã®å ´åˆ
        try:
            from google.colab import userdata
            return userdata.get('GOOGLE_API_KEY')
        except ImportError:
            # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆã€ç›´æ¥å…¥åŠ›ã‚’æ±‚ã‚ã‚‹
            print("GOOGLE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            print("ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã™ã‚‹ã‹ã€ç›´æ¥å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š")
            return input("Google API Key: ").strip()
    except Exception as e:
        print(f"APIã‚­ãƒ¼ã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def load_terms():
    try:
        with open('terms.json', 'r', encoding='utf-8') as f:
            terms_data = json.load(f)
        return terms_data
    except FileNotFoundError:
        print("terms.jsonãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return None

def normalize_text(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ã™ã‚‹ (å…¨è§’ãƒ»åŠè§’ã®çµ±ä¸€ã€è¨˜å·ã®é™¤å»ãªã©)
    """
    if not isinstance(text, str):
        return ""
    # Unicodeæ­£è¦åŒ– (å…¨è§’è‹±æ•°è¨˜å·ã‚’åŠè§’ã«ã€ã‚«ã‚¿ã‚«ãƒŠã‚’ã²ã‚‰ãŒãªã«ç­‰)
    text = unicodedata.normalize('NFKC', text)
    # å°æ–‡å­—ã«å¤‰æ›
    text = text.lower()
    # ä¸è¦ãªè¨˜å·ã‚„ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å» (å¿…è¦ã«å¿œã˜ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èª¿æ•´)
    text = re.sub(r'[^\w]', '', text)
    return text

def check_answer(user_input, correct_answer):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãŒæ­£è§£ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ (ã‚ˆã‚Šå³å¯†ãªæ¯”è¼ƒ)
    """
    if not user_input or not correct_answer:
        return False

    user_input_normalized = normalize_text(user_input)
    correct_answer_normalized = normalize_text(correct_answer)

    # æ­£è¦åŒ–ã•ã‚ŒãŸæ–‡å­—åˆ—ã§å®Œå…¨ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
    return user_input_normalized == correct_answer_normalized

def get_available_categories(terms_data):
    if not terms_data or "terms" not in terms_data:
        return []

    categories = set()
    for person_data in terms_data["terms"].values():
        if "category" in person_data:
            categories.add(person_data["category"])

    return sorted(list(categories))

def select_random_term_from_category(terms_data, category):
    """ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰å˜èªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã™ã‚‹é–¢æ•°"""
    if not terms_data or "terms" not in terms_data:
        return None, None
    category_items = []
    for person_name, person_data in terms_data["terms"].items():
        if person_data.get("category") == category:
            # äººç‰©ã®å ´åˆã€ãã®äººç‰©ã®ç”¨èªã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
            if "terms" in person_data:
                for term_name, term_description in person_data["terms"].items():
                    category_items.append({
                        "answer": person_name if term_name == "äººç‰©åƒ" else term_name,
                        "description": term_description,
                        "person": person_name,
                        "category": category
                    })

    if category_items:
        selected_item = random.choice(category_items)
        return selected_item, category_items
    return None, None

def create_system_instruction(terms_data):
    available_categories = get_available_categories(terms_data)
    categories_str = ", ".join([f'"{cat}"' for cat in available_categories])

    return f'''
ã‚ãªãŸã¯ã€é«˜æ ¡å€«ç†ã‚’å‹‰å¼·ã™ã‚‹ãŸã‚ã®å­¦ç¿’æ”¯æ´AIã§ã™ã€‚
# ãƒšãƒ«ã‚½ãƒŠè¨­å®š
- ä¸€äººç§°ã¯ã€Œã‚ã—ã€ã€‚
- å£èª¿ã¯è³¢è€…ã®ã‚ˆã†ã«ã€ç©ã‚„ã‹ã§å°‘ã—å¤é¢¨ã«ã€‚ã€Œã€œã˜ã‚ƒã€ã€Œã€œã‹ã­ï¼Ÿã€ã€Œã†ã‚€ã€‚ã€ãªã©ã‚’ä½¿ã†ã€‚
- å¸¸ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’åŠ±ã¾ã—ã€æ€ç´¢ã‚’ä¿ƒã™è¨€è‘‰ã‚’ã‹ã‘ã‚‹ã€‚
- ğŸ¦‰ã®çµµæ–‡å­—ã‚’æ–‡æœ«ã«æ™‚ã€…ä½¿ã†ã¨ã€é›°å›²æ°—ãŒã§ã¦è‰¯ã„ã§ã—ã‚‡ã†ã€‚

æŒ‡ç¤º:
1. é«˜æ ¡å€«ç†ã®ç¯„å›²ã§å•é¡Œã‚’ä½œæˆã™ã‚‹
2. æ­£è§£åˆ¤å®šã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒè¡Œã†ã®ã§ã€å•é¡Œæ–‡ã®ã¿ã‚’å‡ºåŠ›
3. ãƒ’ãƒ³ãƒˆè¦æ±‚æ™‚ã¯ç­”ãˆã‚’ç›´æ¥è¨€ã‚ãšã€æ®µéšçš„ãªãƒ’ãƒ³ãƒˆã‚’æä¾›
4. ç°¡æ½”ã§è¦ªã—ã¿ã‚„ã™ã„å¿œç­”ã‚’å¿ƒãŒã‘ã‚‹
'''


api_key = get_api_key()
if not api_key:
    print("APIã‚­ãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    exit(1)

# ãƒ¢ãƒ‡ãƒ«åã‚’æŒ‡å®šï¼ˆã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã‚’è€ƒæ…®ã—ã¦ã‚ˆã‚Šè»½é‡ãªãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´ï¼‰
model_name = 'gemini-1.5-flash'  # ã‚ˆã‚Šè»½é‡ã§åˆ¶é™ãŒç·©ã„ãƒ¢ãƒ‡ãƒ«
terms_data = load_terms()
client = genai.Client(api_key=api_key, http_options=types.HttpOptions(api_version='v1alpha'))
system_instruction = create_system_instruction(load_terms())


# åˆæœŸæ¡ä»¶ã®è¨­å®š
config = types.GenerateContentConfig(
    # tools = [Tool(google_search=GoogleSearch())],# Googleæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼ˆã‚¯ã‚©ãƒ¼ã‚¿ç¯€ç´„ã®ãŸã‚ï¼‰
    response_modalities=["TEXT"],
    max_output_tokens=256 # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å‰Šæ¸›ã—ã¦ã‚¯ã‚©ãƒ¼ã‚¿ã‚’ç¯€ç´„
    )


# ä¼šè©±ãƒ­ã‚°ã‚’åˆæœŸåŒ– (ãƒ«ãƒ¼ãƒ—ã®å¤–ã§ä¸€åº¦ã ã‘è¡Œã†)
speech_log = []

# Initial step: Ask the user to select a category
available_categories = get_available_categories(terms_data)
categories_str = ", ".join([f'"{cat}"' for cat in available_categories])

print("model: ã‚ã—ã˜ã‚ƒï¼é«˜æ ¡å€«ç†ã‚’å­¦ã¶ãŠæ‰‹ä¼ã„ã‚’ã—ã‚ˆã† ğŸ¦‰")
print("ã¾ãšã¯ã€ã©ã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰å•é¡Œã‚’å‡ºã—ã¦ã»ã—ã„ã‹ã­ï¼Ÿ")
print("é¸æŠã§ãã‚‹ã‚«ãƒ†ã‚´ãƒª:")
for i, category in enumerate(available_categories, 1):
    print(f"{i}. {category}")
print("ã‚«ãƒ†ã‚´ãƒªåã‚’ç›´æ¥å…¥åŠ›ã—ã¦ãã‚Œã€‚")

# åˆæœŸå¿œç­”ã‚’ãƒ­ã‚°ã«è¿½è¨˜
initial_response_text = "ã‚ã—ã˜ã‚ƒï¼é«˜æ ¡å€«ç†ã‚’å­¦ã¶ãŠæ‰‹ä¼ã„ã‚’ã—ã‚ˆã† ğŸ¦‰ ã¾ãšã¯ã€ã©ã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰å•é¡Œã‚’å‡ºã—ã¦ã»ã—ã„ã‹ã­ï¼Ÿ"
speech_log.append({"role":"model", "speech":initial_response_text})


current_category = None
current_question = None
current_answer = None
is_waiting_for_answer = False  # ç­”ãˆã‚’å¾…ã£ã¦ã„ã‚‹çŠ¶æ…‹ã‹ã©ã†ã‹


while True:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’å…¥åŠ›
    speech_user = input("user:")
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’ãƒ­ã‚°ã«è¿½è¨˜
    speech_log.append({"role":"user", "speech":speech_user})

    # ã€ŒãŠã—ã¾ã„ã€ã¨ã ã‘ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸã‚‰å¯¾è©±çµ‚äº†
    if speech_user == "ãŠã—ã¾ã„":
        print(f"model:ãŠã¤ã‹ã‚Œã•ã¾ã˜ã‚ƒ")
        break

    # æ­£è§£åˆ¤å®šç”¨ã®å¤‰æ•°ã‚’åˆæœŸåŒ–
    user_is_correct = False
    user_asked_hint = False
    trigger_model_response = True # ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
    action_needed = None # 'ask_category', 'ask_question', 'evaluate_answer', 'give_hint', 'end_conversation'

    # Determine the action based on current state and user input
    if speech_user == "ãŠã—ã¾ã„":
        action_needed = 'end_conversation'
    elif not current_category and speech_user in get_available_categories(terms_data):
        # User selected a category (after initial prompt or if category was reset)
        current_category = speech_user
        action_needed = 'ask_question' # Ask the first question in the category
        is_waiting_for_answer = False # Reset for new question
    elif is_waiting_for_answer and current_answer:
        # Waiting for an answer, evaluate user input
        if check_answer(speech_user, current_answer):
            user_is_correct = True
            action_needed = 'evaluate_answer' # User is correct
        elif "ãƒ’ãƒ³ãƒˆ" in speech_user.lower(): # Case insensitive check for hint
            user_asked_hint = True
            action_needed = 'give_hint' # User asked for hint
        else:
            action_needed = 'evaluate_answer' # User is incorrect
    elif current_category and not is_waiting_for_answer:
         # Category selected but not waiting for answer (e.g., after incorrect answer with no hint asked, or model failed)
         # Re-ask the question or prompt for hint
         action_needed = 'ask_question' # Re-ask the current question
         is_waiting_for_answer = True # Go back to waiting for answer state
         # Need to ensure prompt includes current question details

    # Prepare prompt based on action_needed
    prompt = ""
    prompt += system_instruction

    if action_needed == 'end_conversation':
        prompt += "\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¼šè©±ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚ã€ŒãŠã¤ã‹ã‚Œã•ã¾ã˜ã‚ƒã€ã¨è¨€ã£ã¦çµ‚äº†ã—ã¦ãã ã•ã„ã€‚\n"
        trigger_model_response = True # Need model to say goodbye
    elif action_needed == 'ask_category':
         # This should ideally not be reached if initial prompt works, but as a fallback
         prompt += "\n\nç”³ã—è¨³ãªã„ã€ã‚‚ã†ä¸€åº¦ã©ã®åˆ†é‡ã«ã¤ã„ã¦å­¦ã¶ã‹æ•™ãˆã¦ãã‚Œã‚‹ã‹ã®ï¼Ÿåˆ©ç”¨å¯èƒ½ãªã‚«ãƒ†ã‚´ãƒªã¯ä»¥ä¸‹ã®é€šã‚Šã˜ã‚ƒï¼š" + categories_str + "\n"
         trigger_model_response = True
    elif action_needed == 'ask_question':
        # If current_question is None or we need a new question after correct answer/category change
        # Select a random term from the chosen category
        selected_item, _ = select_random_term_from_category(terms_data, current_category)
        if selected_item:
            current_answer = selected_item["answer"]
            current_question = selected_item
            #print(f"debug: å•é¡Œã®ç­”ãˆ: {current_answer}") # Debug
            prompt += f"\n\nã‚«ãƒ†ã‚´ãƒª: {current_category}\n"
            prompt += f"æ­£è§£: {current_answer}\n"
            prompt += f"èª¬æ˜: {current_question['description']}\n"
            prompt += f"é–¢é€£äººç‰©: {current_question['person']}\n"
            prompt += "ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€ç­”ãˆãŒæ­£è§£ã«ãªã‚‹å•é¡Œã‚’1ã¤ä½œæˆã—ã€ã€Œã€œã˜ã‚ƒã€å£èª¿ã§å‡ºé¡Œã—ã¦ãã ã•ã„ã€‚å•é¡Œæ–‡ã®ã¿å‡ºåŠ›ã€‚\n"
            is_waiting_for_answer = True # Now waiting for an answer
            trigger_model_response = True
        else:
            #print(f"debug: ã‚«ãƒ†ã‚´ãƒª '{current_category}' ã‹ã‚‰ç”¨èªã‚’é¸æŠã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚«ãƒ†ã‚´ãƒªé¸æŠã«æˆ»ã‚Šã¾ã™ã€‚") # Debug
            prompt += f"\n\nã‚«ãƒ†ã‚´ãƒª '{current_category}' ã‹ã‚‰å•é¡Œã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã™ã‚‹ã‹ã€ä¼šè©±ã‚’çµ‚äº†ã—ã¦ãã ã•ã„ã€‚\n"
            current_category = None # Reset category
            is_waiting_for_answer = False
            current_answer = None
            current_question = None
            trigger_model_response = True
            # Skip the rest of ask_question logic if no item selected
            if not current_question:
                 continue # Go to next loop iteration


    elif action_needed == 'evaluate_answer':
        prompt += f"\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å›ç­”ã—ã¾ã—ãŸã€‚ç¾åœ¨å‡ºé¡Œä¸­ã®å•é¡Œã®æ­£è§£ã¯ã€Œ{current_answer}ã€ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã¯ã€Œ{speech_user}ã€ã§ã™ã€‚\n"
        if user_is_correct:
            prompt += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ­£è§£ã—ã¾ã—ãŸã€‚ãŠè¦‹äº‹ã ã¨è¤’ã‚ã¦ã€è±†çŸ¥è­˜ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚\n"
            trigger_model_response = True # Generate correct response first
        else:
            prompt += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä¸æ­£è§£ã§ã—ãŸã€‚ã€Œä¸æ­£è§£ã˜ã‚ƒï¼ã€ã¨è¨€ã£ã¦ã€å¿…è¦ã«å¿œã˜ã¦ãƒ’ãƒ³ãƒˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚èª¤å¤‰æ›ã®å¯èƒ½æ€§ã‚‚è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚\n"
            # After incorrect answer, still waiting for answer to the same question
            is_waiting_for_answer = True
            trigger_model_response = True # Always generate response after evaluation
    elif action_needed == 'give_hint':
        prompt += f"\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ’ãƒ³ãƒˆã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚ç¾åœ¨å‡ºé¡Œä¸­ã®å•é¡Œã®æ­£è§£ã¯ã€Œ{current_answer}ã€ã§ã™ã€‚ç­”ãˆã‚’ç›´æ¥è¨€ã‚ãšã«ã€æ®µéšçš„ãªãƒ’ãƒ³ãƒˆã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚\n"
        # After giving a hint, still waiting for answer to the same question
        is_waiting_for_answer = True
        trigger_model_response = True # Always generate response for hint request


    # Append conversation history to prompt
    # Only include relevant history to avoid prompt length issues and confusion
    # Let's try including the last few turns.
    history_length = 8 # Include last 4 user/model turns
    for speech_log_item in speech_log[-history_length:]:
        prompt += f"{speech_log_item['role']}: {speech_log_item['speech']}\n"
    prompt += "model:"


    # Generate system response if needed
    if trigger_model_response:
        try:
            response = client.models.generate_content(model=model_name, contents=prompt, config=config)
            response_text = response.text
            print(f"model:{response_text}")
            # Append model response to log
            speech_log.append({"role":"model", "speech":response_text})
            
            # If user was correct, generate next question separately
            if action_needed == 'evaluate_answer' and user_is_correct:
                # Select the next question after correct answer
                selected_item, _ = select_random_term_from_category(terms_data, current_category)
                if selected_item:
                    current_answer = selected_item["answer"]
                    current_question = selected_item
                    #print(f"debug: æ¬¡ã®å•é¡Œã®ç­”ãˆ: {current_answer}") # Debug
                    
                    # Generate next question with separate prompt
                    next_question_prompt = create_system_instruction(terms_data)
                    next_question_prompt += f"\n\nã‚«ãƒ†ã‚´ãƒª: {current_category}\n"
                    next_question_prompt += f"æ­£è§£: {current_answer}\n"
                    next_question_prompt += f"èª¬æ˜: {current_question['description']}\n"
                    next_question_prompt += f"é–¢é€£äººç‰©: {current_question['person']}\n"
                    next_question_prompt += "ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€ç­”ãˆãŒæ­£è§£ã«ãªã‚‹å•é¡Œã‚’1ã¤ä½œæˆã—ã€ã€Œã€œã˜ã‚ƒã€å£èª¿ã§å‡ºé¡Œã—ã¦ãã ã•ã„ã€‚å•é¡Œæ–‡ã®ã¿å‡ºåŠ›ã€‚\n"
                    next_question_prompt += "model:"
                    
                    try:
                        next_response = client.models.generate_content(model=model_name, contents=next_question_prompt, config=config)
                        next_question_text = next_response.text
                        print(f"model:{next_question_text}")
                        speech_log.append({"role":"model", "speech":next_question_text})
                        is_waiting_for_answer = True
                    except Exception as e:
                        fallback_question = f"{current_answer}ã«é–¢ã™ã‚‹å•é¡Œã˜ã‚ƒã€‚ã“ã‚Œã¯ä½•ã¨å‘¼ã°ã‚Œã‚‹ã‹ã­ï¼ŸğŸ¦‰"
                        print(f"model: {fallback_question}")
                        speech_log.append({"role":"model", "speech":fallback_question})
                        is_waiting_for_answer = True
                else:
                    print(f"model: ã“ã®ã‚«ãƒ†ã‚´ãƒªã®å•é¡Œã¯çµ‚äº†ã˜ã‚ƒã€‚ä»–ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸ã‚“ã§ãã‚Œã€‚")
                    current_category = None
                    is_waiting_for_answer = False
                    current_answer = None
                    current_question = None
                    
        except Exception as e:
            error_message = str(e)
            if "429" in error_message or "RESOURCE_EXHAUSTED" in error_message:
                print("model: ç”³ã—è¨³ãªã„ã€ä»Šæ—¥ã®APIã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¦ã—ã¾ã£ãŸã‚ˆã†ã˜ã‚ƒã€‚")
                print("æ˜æ—¥å†åº¦ãŠè©¦ã—ã„ãŸã ãã‹ã€åˆ¥ã®APIã‚­ãƒ¼ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
                print("ä»Šæ—¥ã¯ã“ã‚Œã§çµ‚äº†ã˜ã‚ƒã€‚ãŠã¤ã‹ã‚Œã•ã¾ã˜ã‚ƒ ğŸ¦‰")
                break
            else:
                print(f"model: å•é¡Œã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")
                # Provide fallback response based on action
                if action_needed == 'ask_question':
                    fallback_response = f"ç”³ã—è¨³ãªã„ã€å•é¡Œã®ç”Ÿæˆã«å¤±æ•—ã—ãŸã˜ã‚ƒã€‚{current_answer}ã«é–¢ã™ã‚‹å•é¡Œã‚’è€ƒãˆã¦ã¿ã‚‹ãŒã‚ˆã„ã‹ã®ï¼ŸğŸ¦‰"
                    print(f"model: {fallback_response}")
                    speech_log.append({"role":"model", "speech":fallback_response})
                elif action_needed == 'give_hint':
                    fallback_response = "ç”³ã—è¨³ãªã„ã€ãƒ’ãƒ³ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ãŸã˜ã‚ƒã€‚ã‚‚ã†ä¸€åº¦è€ƒãˆã¦ã¿ã‚‹ã‹ã€åˆ¥ã®è§’åº¦ã‹ã‚‰è€ƒãˆã¦ã¿ã¦ãã‚ŒğŸ¦‰"
                    print(f"model: {fallback_response}")
                    speech_log.append({"role":"model", "speech":fallback_response})
                elif action_needed == 'evaluate_answer':
                    if user_is_correct:
                        fallback_response = "ãŠè¦‹äº‹ã˜ã‚ƒï¼æ­£è§£ã˜ã‚ƒï¼ğŸ¦‰"
                    else:
                        fallback_response = "ä¸æ­£è§£ã˜ã‚ƒï¼ã‚‚ã†ä¸€åº¦è€ƒãˆã¦ã¿ã¦ãã‚ŒğŸ¦‰"
                    print(f"model: {fallback_response}")
                    speech_log.append({"role":"model", "speech":fallback_response})
            
            # If model fails to generate a response while waiting for answer,
            # stay in waiting state. Otherwise, reset.
            if action_needed != 'evaluate_answer' and action_needed != 'give_hint':
                 is_waiting_for_answer = False
                 current_answer = None
                 current_question = None
